\label{anexo:scripts}

En la sección \ref{sec:caracterizacion} se describen los pasos del proceso de caracterización de datos de trayectorias individuales. En este anexo se presentan los scripts utilizados para llevar a cabo dicho proceso.

% --------------------------
% Exploración inicial del conjunto de datos
% --------------------------
\begin{lstlisting}[
  language=Python,
  caption={csv\_glance.py, exploración inicial del conjunto de datos.},
  label={cod:csv_glance}
  ]
  import dask.dataframe as dd
  import sys 

  print("Exploracion inicial de datos con Dask\n")

  if len(sys.argv) < 2:
      print("Error: Debe especificar un archivo CSV")
      sys.exit(1)

  ruta_archivo = sys.argv[1]

  ddf = dd.read_csv(
      ruta_archivo,
      encoding="utf-8",  
      sep=",",           
      dtype="object",    
  )

  columnas = ddf.columns.tolist()

  print("Columnas y 2 ejemplos por cada una:\n")
  for col in columnas:
      ejemplos = ddf[col].head(2).values.tolist()
      print(f"- {col}: {ejemplos}")

  input("Presiona Enter para continuar...")
\end{lstlisting}
\vfill

% --------------------------
% Conteo de registros en el conjunto de datos
% --------------------------
\begin{lstlisting}[
  language=Python,
  caption={csv\_count\_registers.py, conteo de registros en el conjunto de datos.},
  label={cod:csv_count}
  ] 
  import dask.dataframe as dd
  import sys
  import os

  def contar_registros(ruta_archivo):

      columnas_usar = ["record_id"]
      try:
          print(f"\nCargando archivo {ruta_archivo}...")
          ddf = dd.read_csv(
              ruta_archivo,
              usecols=columnas_usar,
              sep=",",
              dtype={"record_id": "str"},
              blocksize="256MB",
          )

          print("Contando registros (paciencia para archivos grandes)...")
          total_registros = ddf.shape[0].compute()

          print(f"\nAnalisis completado:")
          print(f"Archivo analizado: {ruta_archivo}")
          print(f"Total de registros: {total_registros:,}")

      except Exception as e:
          print(f"\nOcurrio un error inesperado: {str(e)}")

  if __name__ == "__main__":
      print("=== Contador de registros en archivos CSV grandes ===")

      if len(sys.argv) < 2:
          print("Uso: python csv_count_registers.py <nombre_del_archivo.csv>")
          sys.exit(1)

      archivo = sys.argv[1]
      contar_registros(archivo)
\end{lstlisting}
\vfill

% --------------------------
% Eliminación de campos innecesarios
% --------------------------
\begin{lstlisting}[
  language=Python,
  caption={remove\_columns.py, eliminación de campos innecesarios en el conjunto de datos.},
  label={cod:csv_slim}
  ]
  import dask.dataframe as dd

  columnas_deseadas = [
    'identifier',
    'timestamp',
    'device_lat',
    'device_lon',
    'device_horizontal_accuracy',
    'record_id',
    'time_zone_name'
  ]

  df = dd.read_csv('Mobility_Data.csv', usecols=columnas_deseadas)

  df.to_csv('Mobility_Data_Slim.csv', index=False, single_file=True, encoding='utf-8-sig')
\end{lstlisting}
\vfill
% --------------------------
% Obtención de valores únicos
% --------------------------
\begin{lstlisting}[
  language=Python,
  breaklines=true,
  caption={unique\_values.py, obtención de valores únicos de la columna 'device\_horizontal\_accuracy'.},
  label={cod:unique_values}
  ]
  import pandas as pd
  from tqdm import tqdm
  import os
  import sys
  from src.menus.menu import MainMenu
  def main():
      print("\n" + "="*50)
      print(" EXTRACTOR DE VALORES UNICOS DE COLUMNAS CSV")
      print("="*50 + "\n")

      if len(sys.argv) < 2:
          print("Uso: python extract_unique.py <archivo.csv>")
          sys.exit(1)

      csv_file = sys.argv[1]

      if not os.path.exists(csv_file):
          print(f"Error: El archivo '{csv_file}' no existe.")
          sys.exit(1)

      chunk_size = 1_000_000

      try:
          available_columns = pd.read_csv(csv_file, nrows=0).columns.tolist()
      except Exception as e:
          print(f"Error leyendo el archivo: {e}")
          sys.exit(1)

      try:
          selected_index = MainMenu.display_available_columns(available_columns)
          target_column = available_columns[selected_index]
      except (ValueError, IndexError):
          print("Seleccion invalida.")
          sys.exit(1)
      except Exception as e:
          print(f"Error inesperado al seleccionar columna: {e}")
          sys.exit(1)

      safe_column_name = target_column.replace(" ", "_").replace("/", "_")
      output_file = f"valores_unicos_{safe_column_name}.txt"

      unique_values = set()
      print(f"\nProcesando columna: {target_column}\n")

      try:
          for chunk in tqdm(pd.read_csv(csv_file, usecols=[target_column], chunksize=chunk_size)):
              unique_values.update(chunk[target_column].dropna().astype(str))
      except Exception as e:
          print(f"Error durante el procesamiento: {e}")
          sys.exit(1)

      try:
          numeric_values = sorted([float(v) for v in unique_values])
          is_numeric = True
      except ValueError:
          is_numeric = False

      try:
          with open(output_file, "w", encoding="utf-8") as f:
              if is_numeric:
                  min_val = numeric_values[0]
                  max_val = numeric_values[-1]
                  f.write(f"# Rango de valores: {min_val} - {max_val}\n")
                  f.write("\n".join(str(v) for v in numeric_values))
              else:
                  sorted_values = sorted(unique_values)
                  f.write("# Rango de valores: No numerico\n")
                  f.write("\n".join(sorted_values))
      except Exception as e:
          print(f"Error guardando los resultados: {e}")
          sys.exit(1)

      print(f"\nSe encontraron {len(unique_values):,} valores unicos.")
      print(f"Resultados guardados en: {output_file}")

      print("\nMuestra de valores unicos (primeros 10):")
      print("\n".join(sorted(unique_values)[:10]))

  if __name__ == "__main__":
      main()
\end{lstlisting}
\vfill

\begin{lstlisting}[
  language=Python,
  caption={accuracy\_histogram.py, creación de un histograma de frecuencias de la columna 'device\_horizontal\_accuracy'.},
  label={cod:accuracy_histogram}
  ]
  import os
  import pandas as pd
  import matplotlib.pyplot as plt
  import numpy as np

  archivo_csv = "Mobility_Data_Slim.csv"
  columna = "device_horizontal_accuracy"  
  bins = 100 
  os.makedirs("img", exist_ok=True) 

  frecuencias = pd.Series(dtype=float)
  for chunk in pd.read_csv(archivo_csv, usecols=[columna], chunksize=1_000_000):
    frecuencias = pd.concat([frecuencias, chunk[columna].value_counts()])

  counts, edges = np.histogram(frecuencias.index, bins=bins, weights=frecuencias.values)

  plt.figure(figsize=(12, 6))
  plt.bar(edges[:-1], counts, width=np.diff(edges), align='edge', edgecolor='black', alpha=0.7)
  plt.title("Frecuencias de Valores Agrupados por Rangos (0-200)")
  plt.xlabel("Rango de Valores")
  plt.ylabel("Frecuencia Total (Millones)")
  plt.xticks(edges[::5], rotation=45) 
  plt.grid(axis='y', linestyle='--')

  output_path = "img/histograma_frecuencias_rangos.png"
  plt.savefig(output_path, dpi=300, bbox_inches='tight')
  plt.close()
\end{lstlisting}
\vfill

\begin{lstlisting}[
    language=Python,
    caption={identifier\_histogram.py, creación de un histograma de frecuencias de la columna 'identifier'.},
    label={cod:identifier_histogram}
    ]
    import os
    import pandas as pd
    import matplotlib.pyplot as plt
    import numpy as np
    from collections import Counter

    archivo_csv = "Mobility_Data_Slim.csv"
    columna = "identifier"  
    chunksize = 1_000_000  
    os.makedirs("img", exist_ok=True) 

    counter = Counter()
    for chunk in pd.read_csv(archivo_csv, usecols=[columna], chunksize=chunksize):
        counter.update(chunk[columna].dropna().astype(str))

    frecuencias = pd.Series(counter)

    max_freq = frecuencias.max()
    bins = [0] + [10**i for i in range(0, int(np.log10(max_freq)) + 2)]  # Ej: [0, 1, 10, 100, 1000, ...]
    frecuencias_agrupadas = pd.cut(frecuencias, bins=bins, right=False).value_counts().sort_index()

    plt.figure(figsize=(12, 7))
    frecuencias_agrupadas.plot(kind='bar', logy=True, alpha=0.7, edgecolor='black')

    plt.xticks(rotation=45, ha='right')  # Rotar etiquetas para mejor legibilidad
    plt.title("Distribucion de Frecuencias Agrupadas en Bloques de 1000 Repeticiones")
    plt.xlabel("Rango de repeticiones (ej: [0, 1000) significa 0-999 repeticiones)")
    plt.ylabel("Cantidad de valores unicos (log)")
    plt.grid(True, which="both", ls="--", axis='y')

    output_path = os.path.join("img", "histograma_frecuencias_agrupadas_1000.png")
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
\end{lstlisting}
\vfill

\begin{lstlisting}[
    language=Python,
    caption={identifier\_histogram\_detailed.py, análisis de frecuencias de la columna 'identifier'.},
    label={cod:identifier_histogram_detailed}
    ]
    import os
    import pandas as pd
    import matplotlib.pyplot as plt
    import numpy as np
    from collections import Counter

    archivo_csv = "Mobility_Data_Slim.csv"
    columna = "identifier"  
    chunksize = 1_000_000  
    os.makedirs("img", exist_ok=True)

    counter = Counter()
    for chunk in pd.read_csv(archivo_csv, usecols=[columna], chunksize=chunksize):
        counter.update(chunk[columna].dropna().astype(str))
    frecuencias = pd.Series(counter)

    frecuencias_bajas = frecuencias[(frecuencias >= 1) & (frecuencias <= 99)]
    frecuencias_medias = frecuencias[(frecuencias >= 100) & (frecuencias <= 1000)]
    frecuencias_altas = frecuencias[(frecuencias >= 1001) & (frecuencias <= 10000)]

    bins_bajas = list(range(1, 100, 10))  # 1-99 en pasos de 10 
    bins_medias = list(range(100, 1001, 100))  # 100-1000 en pasos de 100
    bins_altas = list(range(1001, 10001, 1000))  # 1001-10000 en pasos de 1000

    freciencias_bajas_agrupadas = pd.cut(frecuencias_bajas, bins=bins_bajas, right=False).value_counts().sort_index()
    frecuencias_medias_agrupadas = pd.cut(frecuencias_medias, bins=bins_medias, right=False).value_counts().sort_index()
    frecuencias_altas_agrupadas = pd.cut(frecuencias_altas, bins=bins_altas, right=False).value_counts().sort_index()

    print("\n=== Resumen de frecuencias ===")
    print(f"\n**Rango 1-100 repeticiones**:")
    print(f" - Total de valores unicos: {len(frecuencias_bajas)}")
    print(f"\n**Rango 100-1000 repeticiones**:")
    print(f" - Total de valores unicos: {len(frecuencias_medias)}")
    print(f"\n**Rango 1000-10000 repeticiones**:")
    print(f" - Total de valores unicos: {len(frecuencias_altas)}")


    plt.figure(figsize=(10, 6))
    freciencias_bajas_agrupadas.plot(kind='bar', color='skyblue', edgecolor='black', alpha=0.7)
    plt.title("Distribucion de Frecuencias (1-100 repeticiones)")
    plt.xlabel("Rango de repeticiones")
    plt.ylabel("Cantidad de valores unicos")
    plt.xticks(rotation=45)
    plt.grid(axis='y', linestyle='--')
    plt.tight_layout()
    plt.savefig(os.path.join("img", "histograma_1_100.png"), dpi=300)
    plt.close()

    plt.figure(figsize=(10, 6))
    frecuencias_medias_agrupadas.plot(kind='bar', color='skyblue', edgecolor='black', alpha=0.7)
    plt.title("Distribucion de Frecuencias (100-1000 repeticiones)")
    plt.xlabel("Rango de repeticiones")
    plt.ylabel("Cantidad de valores unicos")
    plt.xticks(rotation=45)
    plt.grid(axis='y', linestyle='--')
    plt.tight_layout()
    plt.savefig(os.path.join("img", "histograma_100_1000.png"), dpi=300)
    plt.close()

    plt.figure(figsize=(10, 6))
    frecuencias_altas_agrupadas.plot(kind='bar', color='salmon', edgecolor='black', alpha=0.7)
    plt.title("Distribucion de Frecuencias (1001-10,000 repeticiones)")
    plt.xlabel("Rango de repeticiones")
    plt.ylabel("Cantidad de valores unicos")
    plt.xticks(rotation=45)
    plt.grid(axis='y', linestyle='--')
    plt.tight_layout()
    plt.savefig(os.path.join("img", "histograma_1001_10000.png"), dpi=300)
    plt.close()

    print("Graficos guardados en /img/")
\end{lstlisting}
\vfill